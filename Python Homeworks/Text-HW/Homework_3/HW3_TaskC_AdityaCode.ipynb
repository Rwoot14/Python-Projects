{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "no such group",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b9fe1752fd4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mreviews_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Edmunds Reviews.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mbrand_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ES'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'A8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'A6'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3Series'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'5Series'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'7Series'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'XJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SClass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0msentiment_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrand_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[0medge_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# print edge_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b9fe1752fd4a>\u001b[0m in \u001b[0;36msentiment_scores\u001b[1;34m(reviews_data, brand_list)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0msent_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mreview_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0msent_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment_review\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrand_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbrand_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0msent_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b9fe1752fd4a>\u001b[0m in \u001b[0;36msentiment_review\u001b[1;34m(review, brand_list)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msent_score_fin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: no such group"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "import pylab\n",
    "\n",
    "def sentiment_review(review, brand_list):\n",
    "    review = re.sub(\"\\\"\", \"\", review)\n",
    "    # review = re.sub(\"\")\n",
    "    \n",
    "    for item in brand_list:\n",
    "        iter = re.finditer(item, review)\n",
    "        if iter:\n",
    "            sentiment = []\n",
    "            for m in iter:\n",
    "                sentence = review[max(0, m.start(0-70)): min((m.start(0) + len(item)+70), len(review))]\n",
    "                                  \n",
    "    return sent_score_fin\n",
    "\n",
    "def sentiment_scores(reviews_data, brand_list):\n",
    "    \"\"\"\n",
    "    gets the value of sentiment for each review for all the brands,\n",
    "    PARAM reviews_data: Raw input of reviews data\n",
    "    PARAM brand_list: list of brands to be considered\n",
    "    RETURN: a dictionary of sentiment scores by key post\n",
    "    \"\"\"\n",
    "    sent_scores = {}\n",
    "    for item in brand_list:\n",
    "        sent_scores[item]=list()\n",
    "    for review_id in range(0, len(reviews_data)):\n",
    "        sent_values = sentiment_review(reviews_data.iloc[review_id, 0], brand_list)\n",
    "        for item in brand_list:\n",
    "            sent_scores[item].append(sent_values[item])\n",
    "    fin = pd.DataFrame.from_dict(sent_scores, orient='columns')\n",
    "    fin.to_csv('Sentiment_Scores.csv', index=False)\n",
    "    return sent_scores\n",
    "\n",
    "def create_edges(sent_scores):\n",
    "    \"\"\"\n",
    "    Calculates the edgeweight by row. If it is positive it is added\n",
    "    to a list of positive sentiment, else to a list of negative sentiment.\n",
    "    The edge from x->y is weighed as mean of positive sentiment list.\n",
    "    The edge from y->x is weighed as absolut evalue of the mean of negative sentiment list.\n",
    "    PARAM sent_scores: dictionary lists as value for keys\n",
    "    RETURN: edge_list: list of lists\n",
    "    \"\"\"\n",
    "    edge_list = []\n",
    "    brand_list = sent_scores.keys()\n",
    "    # print brand_list, len(sent_scores[brand_list[0]])\n",
    "    for x in range(0, len(brand_list)):\n",
    "        for y in range(x+1, len(brand_list)):\n",
    "            positive_sent = []\n",
    "            negative_sent = []\n",
    "            for i in range(0, len(sent_scores[brand_list[0]])):\n",
    "                sent_x = sent_scores[brand_list[x]][i]\n",
    "                sent_y = sent_scores[brand_list[y]][i]\n",
    "                # print i, brand_list[x], brand_list[y], sent_x, sent_y\n",
    "                if (not(np.isnan(sent_x))) & (not(np.isnan(sent_y))):\n",
    "                    edge_weight = sent_x - sent_y\n",
    "                    if edge_weight >= 0:\n",
    "                        positive_sent.append(edge_weight)\n",
    "                    else:\n",
    "                        negative_sent.append(edge_weight)\n",
    "            if len(positive_sent)>0:\n",
    "                # print positive_sent\n",
    "                edge_list.append([brand_list[x], brand_list[y], np.mean(positive_sent)])\n",
    "            if len(negative_sent)>0:\n",
    "                # print negative_sent\n",
    "                edge_list.append([brand_list[y], brand_list[x], abs(np.mean(negative_sent))])\n",
    "    return edge_list\n",
    "\n",
    "def form_network(edge_list):\n",
    "    \"\"\"\n",
    "    Forms a network\n",
    "    Calculates unweighted pagerank\n",
    "    Prints the calculated pagerank values\n",
    "    PARAM edge_list: list of lists\n",
    "    RETURN: None\n",
    "    \"\"\"\n",
    "    directed_graph = nx.DiGraph()\n",
    "    directed_graph.add_weighted_edges_from(edge_list, weight = 'weight')\n",
    "    # nx.draw(directed_graph)\n",
    "    # pylab.show()\n",
    "    # 1-alpha: probability with which the user might click on outgoing link randomly.\n",
    "    # The mentions in the post of a given brand aren't random, hence alpha is made close to 1\n",
    "    pagerank_unweighted = nx.pagerank(directed_graph, alpha=0.99, weight = 1)\n",
    "    print(pagerank_unweighted)\n",
    "    print(len(pagerank_unweighted))\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Reads data and brand list.\n",
    "    Calculates the sentiment of all brands in each review\n",
    "    Forms an edge list based on teh sentiment of the comparisons\n",
    "    Calculates the phage rank of the product\n",
    "    \"\"\"\n",
    "    reviews_data = pd.read_excel('Edmunds Reviews.xlsx', encoding='latin1')\n",
    "    brand_list = ['ES', 'LS', 'RX', 'A8', 'A6', '3Series', '5Series', '7Series', 'XJ', 'SClass']\n",
    "    sentiment_scores = sentiment_scores(reviews_data, brand_list)\n",
    "    edge_list = create_edges(sentiment_scores)\n",
    "    # print edge_list\n",
    "    pagerank = form_network(edge_list)\n",
    "                                  \n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
